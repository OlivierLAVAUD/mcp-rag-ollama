# NexusCore - MCP OLLAMA RAG AGENT
## Search üîç,Analysis üìä and Generate ‚úçÔ∏è on listed web sources

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Un agent conversationnel intelligent impl√©mentant le protocole MCP (Machine Conversation Protocol) avec capacit√©s RAG (Retrieval-Augmented Generation) utilisant Ollama comme backend LLM.


## Pr√©sentation de l'application

Cette application est un agent conversationnel intelligent qui combine plusieurs technologies avanc√©es :

1. **Protocole MCP** : Une impl√©mentation du standard de communication machine-to-machine pour les agents IA, permettant une int√©gration standardis√©e avec d'autres syst√®mes.

2. **RAG avec Ollama** : 
   - Utilisation de mod√®les LLM locaux via Ollama
   - Pipeline complet de traitement des documents (extraction, d√©coupage, embedding)
   - Recherche vectorielle avec FAISS (CPU/GPU)

3. **Architecture multi-agents** :
   - Agent de recherche (combine recherche web et RAG)
   - Agent d'analyse (analyse s√©mantique et statistique)
   - Agent de g√©n√©ration (cr√©ation de contenu)

4. **Fonctionnalit√©s avanc√©es** :
   - Logging structur√© pour le d√©bogage
   - Configuration centralis√©e
   - Support multi-fournisseurs de recherche (Exa, Firecrawl)
   - Gestion automatique des erreurs

L'application est particuli√®rement adapt√©e pour :
- Les assistants virtuels intelligents
- Les syst√®mes de recherche d'information augment√©e
- Les outils d'analyse de contenu
- Les g√©n√©rateurs de contenu automatis√©s

Le syst√®me est con√ßu pour √™tre extensible avec de nouveaux agents et capacit√©s tout en maintenant une architecture propre et modulaire.

## Fonctionnalit√©s cl√©s

- üìö**Recherche augment√©e** : Combinaison de recherche web et RAG pour des r√©ponses pr√©cises
- ü§ñ **Multi-agents** : Architecture modulaire avec agents sp√©cialis√©s
- ‚úÖ**Protocole MCP** : Impl√©mentation du standard de conversation machine-to-machine
- ‚ú®**Int√©gration Ollama** : Utilisation des mod√®les LLM locaux via Ollama
- üìù**Traitement avanc√©** : Extraction, nettoyage et analyse de contenu web

## Architecture technique

```markdown
NexusCore/
‚îÇ
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                 # Main agents (research, analysis, generation)
‚îÇ   ‚îú‚îÄ‚îÄ agent_orchestrator.py    # Agent coordination logic
‚îÇ   ‚îú‚îÄ‚îÄ config.py                # Central configuration
‚îÇ   ‚îú‚îÄ‚îÄ mcp_server.py            # FastAPI MCP implementation
‚îÇ   ‚îú‚îÄ‚îÄ rag.py                   # RAG processing
‚îÇ   ‚îú‚îÄ‚îÄ search.py                # Advanced web search
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ logging_service.py   # Structured logging service
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml               # Project configuration
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îî‚îÄ‚îÄ .env.sample                  # Environment template
```

## Pr√©requis

- Python 3.10+
- Ollama install√© localement avec au moins un mod√®le (ex: `llama3`)
- Cl√© API pour un fournisseur de recherche (Exa ou Firecrawl)


## Installation

0. Ollama

- Installation sur votre systeme (Unix ou Windows) (https://ollama.com/)
-  Charger les modeles LLMs

```bash
# Exemple: Chargement du modele "mistral"
ollama pull mistral

# Lancement du serveur sur une session terminal ind√©pendante.
ollama serve
```

1. Cloner le d√©p√¥t :
```bash
git clone https://github.com/votre-repo/ollama-rag-agent.git
cd ollama-rag-agent
```

2. Installer les d√©pendances :
->  Creer l'environnement avec uv (plus rapide et fiable)
```bash
uv venv .venv

# pour Windows
.venv\scripts\activate 

# pour Unix
source .venv\scripts\activate # Unix

# puis installez les d√©pendances
uv pip install -r requirements.txt
```

3. Configurer l'environnement de l'application et ses param√®tres :
```bash
# √âditer le fichier .env puis ajoutez vos configurations (bas√©e sur  .env sample)
cp .env.sample .env #Unix
edit .env           #Windows

```

## Utilisation
Lancer le serveur MCP

### Lancer le serveur mcp
```bash
cd app
uv run mcp_server.py
```
Le serveur sera accessible sur http://localhost:8000 avec les endpoints suivants :

    . POST /search - Recherche augment√©e
    . POST /analyze - Analyse de texte
    . POST /generate - G√©n√©ration de contenu
    . GET /health - V√©rification de l'√©tat du serveur


### Utilisation en ligne de commande:

```bash
python agent.py "Votre requ√™te ici"
```
ou 

```bash
uv run agent.py "Votre requ√™te ici"
```

## Configuration

Les param√®tres principaux sont configurables via le fichier .env :
```bash
# Mod√®le Ollama
OLLAMA_MODEL=llama3.2
OLLAMA_BASE_URL=http://localhost:11434

# Param√®tres RAG
RAG_CHUNK_SIZE=4096
RAG_CHUNK_OVERLAP=512

# Fournisseur de recherche
SEARCH_PROVIDER=exa  # ou firecrawl
EXA_API_KEY=votre_cle_api
```

## Licence

Ce projet est sous licence MIT - voir le fichier LICENCE.md pour plus de d√©tails.

## Auteur

Olivier Lavaud - 2025


# Technical Documentation
## System Purpose

MCP-RAG-Ollama serves as a versatile query answering system that combines the power of large language models with real-time information retrieval. It enables users to:

    Get answers to questions using contextual knowledge from web searches
    Implement RAG workflows with Ollama models
    Access the system via both API endpoints and command-line interface



## Architecture Overview
The system follows a layered architecture pattern, separating client interactions, server operations, core processing, and external service integrations.
<p align="center"><img src="img/i1.png" alt="[Architecture Overview" width="600" height="400"></p>

## Core Components
The system consists of four main components that work together to provide RAG capabilities:
<p align="center"><img src="img/i2.png" alt="[Core Components" width="600" height="400">
</p>

```bash
    - MCP Server: The FastAPI server that exposes endpoints for client interactions.
    - OllamaAgent: The orchestrator that processes queries by combining web search and RAG.
    - RAG Processor: Handles document processing, embedding generation, and similarity search.
    - Web Searcher: Performs web searches and content extraction from relevant pages.
```

## Query Processing Flow
The following diagram illustrates how a user query flows through the system:

<p align="center"><img src="img/i3.png" alt="[Core Components" width="600" height="400"></p>

## Technology Stack

The MCP-RAG-Ollama system leverages multiple technologies and libraries:

<p align="center"><img src="img/i5.png" alt="[Technology Stack" width="500" height="300"></p>

## Deployment Architecture
The system can be deployed as follows:*

<p align="center"><img src="img/i4.png" alt="Deployment Architecture" width="600" height="400"></p>
