# MCP RAG Agent avec Ollama

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Un agent conversationnel intelligent implÃ©mentant le protocole MCP (Machine Conversation Protocol) avec capacitÃ©s RAG (Retrieval-Augmented Generation) utilisant Ollama comme backend LLM.

## FonctionnalitÃ©s clÃ©s

- ğŸ“š**Recherche augmentÃ©e** : Combinaison de recherche web et RAG pour des rÃ©ponses prÃ©cises
- ğŸ¤– **Multi-agents** : Architecture modulaire avec agents spÃ©cialisÃ©s
- âœ…**Protocole MCP** : ImplÃ©mentation du standard de conversation machine-to-machine
- âœ¨**IntÃ©gration Ollama** : Utilisation des modÃ¨les LLM locaux via Ollama
- ğŸ“**Traitement avancÃ©** : Extraction, nettoyage et analyse de contenu web

## Architecture technique
```bash
.
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ agent.py # Agents principaux (recherche, analyse, gÃ©nÃ©ration)
â”‚ â”œâ”€â”€ agent_orchestrator.py # Orchestration des agents
â”‚ â”œâ”€â”€ config.py # Configuration centrale
â”‚ â”œâ”€â”€ mcp_server.py # Serveur FastAPI implÃ©mentant MCP
â”‚ â”œâ”€â”€ rag.py # Traitement RAG
â”‚ â”œâ”€â”€ search.py # Recherche web avancÃ©e
â”‚ â””â”€â”€ utils/
â”‚ â””â”€â”€ logging_service.py # Service de logging structurÃ©
â”œâ”€â”€ pyproject.toml # Configuration du projet
â”œâ”€â”€ requirements.txt # DÃ©pendances Python
â””â”€â”€ .env.sample # Configuration d'environnement
```
## PrÃ©requis

- Python 3.10+
- Ollama installÃ© localement avec au moins un modÃ¨le (ex: `llama3`)
- ClÃ© API pour un fournisseur de recherche (Exa ou Firecrawl)


## Installation

0. Installer Ollama sur votre systeme (Unix ou Windows)(https://ollama.com/) et charger les modeles LLM
```bash
# Exemple: Chargement du modele "mistral"
ollama pull mistral
# Lancement du serveur le serveur
ollama serve
```

1. Cloner le dÃ©pÃ´t :
```bash
git clone https://github.com/votre-repo/ollama-rag-agent.git
cd ollama-rag-agent
```

2. Creer l'environnement avec uv (plus rapide et fiable) et installer les dÃ©pendances :
```bash
uv venv .venv
.venv\scripts\activate # Windows
source .venv\scripts\activate # Unix

uv pip install -r requirements.txt
```

3. Configurer l'environnement :
```bash
cp .env.sample .env
# Ã‰diter le fichier .env avec vos configurations
```

4. Lancer le serveur mcp
```bash
cd app
uv run mcp_server.py
```
5. Utiliser l'agent en CLI :

```bash
python agent.py "Votre question ici"
```
ou 

```bash
uv run agent.py "Votre question ici"
```


# Technical Documentation

## System Purpose

MCP-RAG-Ollama serves as a versatile query answering system that combines the power of large language models with real-time information retrieval. It enables users to:

    Get answers to questions using contextual knowledge from web searches
    Implement RAG workflows with Ollama models
    Access the system via both API endpoints and command-line interface



## Architecture Overview
The system follows a layered architecture pattern, separating client interactions, server operations, core processing, and external service integrations.
<p align="center"><img src="img/i1.png" alt="[Architecture Overview" width="600" height="400"></p>

## Core Components
The system consists of four main components that work together to provide RAG capabilities:
<p align="center"><img src="img/i2.png" alt="[Core Components" width="600" height="400">
</p>

```bash
    - MCP Server: The FastAPI server that exposes endpoints for client interactions.
    - OllamaAgent: The orchestrator that processes queries by combining web search and RAG.
    - RAG Processor: Handles document processing, embedding generation, and similarity search.
    - Web Searcher: Performs web searches and content extraction from relevant pages.
```

## Query Processing Flow
The following diagram illustrates how a user query flows through the system:

<p align="center"><img src="img/i3.png" alt="[Core Components" width="600" height="400"></p>

## Technology Stack

The MCP-RAG-Ollama system leverages multiple technologies and libraries:

<p align="center"><img src="img/i5.png" alt="[Technology Stack" width="500" height="300"></p>

## Deployment Architecture
The system can be deployed as follows:*

<p align="center"><img src="img/i4.png" alt="Deployment Architecture" width="600" height="400"></p>
