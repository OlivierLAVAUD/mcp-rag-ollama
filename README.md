# MCP-RAG-AI-AGENT
## MCP SEARCH ANALYSIS & GENERATIVE AGENT
## Search üîç,Analysis üìä and Generate ‚úçÔ∏è on listed web sources

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Un agent conversationnel intelligent impl√©mentant le protocole Model Context Protocol (MCP) avec capacit√©s RAG (Retrieval-Augmented Generation) utilisant Ollama comme backend LLM.


## Pr√©sentation de l'application

Cette application est un agent conversationnel intelligent qui combine plusieurs technologies avanc√©es :

1. **Conformit√© avec le Protocole MCP(Model Context Protocol )** : Le Model Context Protocol (MCP) est un cadre standardis√© permettant de d√©finir et de g√©rer le contexte des agents IA, garantissant une meilleure interop√©rabilit√©, tra√ßabilit√© et explicabilit√©. Dans ce syst√®me multi-agents, le MCP permet d‚Äôuniformiser la communication entre agents en encapsulant leurs m√©tadonn√©es, leurs capacit√©s et leurs contraintes.

2. **Architecture RAG & Modeles LLM avec Ollama** : 
   - Utilisation de mod√®les LLM locaux via Ollama
   - Pipeline complet de traitement des documents (extraction, d√©coupage, embedding)
   - Recherche vectorielle avec FAISS (CPU/GPU)

3. **Architecture multi-agents** :
   - Agent de recherche (combine recherche web et RAG)
   - Agent d'analyse (analyse s√©mantique et statistique)
   - Agent de g√©n√©ration (cr√©ation de contenu)

4. **Fonctionnalit√©s avanc√©es** :
   - Logging structur√© pour le d√©bogage
   - Configuration centralis√©e
   - Support multi-fournisseurs de recherche (Exa, Firecrawl)
   - Gestion automatique des erreurs

L'application est particuli√®rement adapt√©e pour :
- Les assistants virtuels intelligents
- Les syst√®mes de recherche d'information augment√©e
- Les outils d'analyse de contenu
- Les g√©n√©rateurs de contenu automatis√©s

Le syst√®me est con√ßu pour √™tre extensible avec de nouveaux agents et capacit√©s tout en maintenant une architecture propre et modulaire.

## Fonctionnalit√©s cl√©s

- üìö**Recherche augment√©e** : Combinaison de recherche web et RAG pour des r√©ponses pr√©cises
- ü§ñ **Multi-agents** : Architecture modulaire avec agents sp√©cialis√©s
- ‚úÖ**Protocole MCP** : Impl√©mentation du standard de conversation machine-to-machine
- ‚ú®**Int√©gration Ollama** : Utilisation des mod√®les LLM locaux via Ollama
- üìù**Traitement avanc√©** : Extraction, nettoyage et analyse de contenu web

## Architecture technique

```markdown
NEXUS-MCP-LLM-RAG/
‚îÇ
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                 # Main agents (research, analysis, generation)
‚îÇ   ‚îú‚îÄ‚îÄ agent_orchestrator.py    # Agent coordination logic
‚îÇ   ‚îú‚îÄ‚îÄ config.py                # Central configuration
‚îÇ   ‚îú‚îÄ‚îÄ mcp_server.py            # FastAPI MCP implementation
‚îÇ   ‚îú‚îÄ‚îÄ rag.py                   # RAG processing
‚îÇ   ‚îú‚îÄ‚îÄ search.py                # Advanced web search
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ logging_service.py   # Structured logging service
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml               # Project configuration
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îî‚îÄ‚îÄ .env.sample                  # Environment template
```

## Pr√©requis

- Python 3.10+
- Ollama install√© localement avec au moins un mod√®le (ex: `llama3`) (https://ollama.com/)
- Cl√© API pour un fournisseur de recherche (Exa ou Firecrawl)


## Installation

- Cloner le d√©p√¥t :
```bash
git clone https://github.com/OlivierLAVAUD/mcp-rag-ollama
cd ollama-rag-agent
```

- Charger les mod√®les LLM √† partir d'ollama et lancer le serveur ollama

```bash
# Exemple: Chargement du modele "mistral"
ollama pull mistral

# Lancement du serveur sur une session terminal ind√©pendante.
ollama serve
```

- Cr√©ez & modifiez votre fichier de configuration/param√®trage .env :
```bash
# Creez le fichier .env sur le template .env sample fournit et modifiez le. (voir Configuration)
```bash
    cp .env.sample .env 
    edit .env           
```

## Utilisation

### Lancer le serveur MCP
```bash
    uv run app/mcp_server.py
```

### Lancer une requ√™te √† l'Agent

```bash
    uv run app/agent.py "Donne moi les derni√®res actualit√©s √† propos des Agents IA"
```

## Configuration

Les param√®tres principaux sont configurables via le fichier .env :
```bash
# Mod√®le Ollama
# === G√©n√©ration Configuration du Mod√®le LLM via Ollama ===
OLLAMA_MODEL=llama3.2
OLLAMA_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=llama3.2

OLLAMA_MODEL_TEMPERATURE=0.7  # Contr√¥le la cr√©ativit√© (0-1)
OLLAMA_MODEL_MAX_TOKENS=1024  # Nombre maximum de tokens g√©n√©r√©s
OLLAMA_MODEL_TOP_P=0.75       # Filtrage par noyau (0-1)

# === Param√®tres RAG ===
RAG_CHUNK_SIZE=4096
RAG_CHUNK_OVERLAP=512
RAG_RESULTS=5

# Fournisseur de recherche
SEARCH_PROVIDER=exa  # ou firecrawl
EXA_API_KEY=votre_cle_api
...

```

## Licence

Ce projet est sous licence MIT - voir le fichier LICENCE.md pour plus de d√©tails.

## Auteur

Olivier Lavaud - 2025


# Technical Documentation
## System Purpose

MCP-RAG-Ollama serves as a versatile query answering system that combines the power of large language models with real-time information retrieval. It enables users to:

    Get answers to questions using contextual knowledge from web searches
    Implement RAG workflows with Ollama models
    Access the system via both API endpoints and command-line interface



## Architecture Overview
The system follows a layered architecture pattern, separating client interactions, server operations, core processing, and external service integrations.
<p align="center"><img src="img/i1.png" alt="[Architecture Overview" width="600" height="400"></p>

## Core Components
The system consists of four main components that work together to provide RAG capabilities:
<p align="center"><img src="img/i2.png" alt="[Core Components" width="600" height="400">
</p>

```bash
    - MCP Server: The FastAPI server that exposes endpoints for client interactions.
    - OllamaAgent: The orchestrator that processes queries by combining web search and RAG.
    - RAG Processor: Handles document processing, embedding generation, and similarity search.
    - Web Searcher: Performs web searches and content extraction from relevant pages.
```

## Query Processing Flow
The following diagram illustrates how a user query flows through the system:

<p align="center"><img src="img/i3.png" alt="[Core Components" width="600" height="400"></p>

## Technology Stack

The MCP-RAG-Ollama system leverages multiple technologies and libraries:

<p align="center"><img src="img/i5.png" alt="[Technology Stack" width="500" height="300"></p>

## Deployment Architecture
The system can be deployed as follows:*

<p align="center"><img src="img/i4.png" alt="Deployment Architecture" width="600" height="400"></p>
