# Configuration Ollama
OLLAMA_MODEL=llama2
OLLAMA_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=mistral

# FAISS Configuration
FAISS_TYPE=cpu  # ou 'gpu' si vous avez installé faiss-gpu

# Paramètres RAG
CHUNK_SIZE=4096
CHUNK_OVERLAP=512
RAG_RESULTS=3

# API Exa/Firecrawl
SEARCH_PROVIDER=exa
EXA_API_KEY=e3f02d15-4fb8-48bd-a785-c496f703844c
FIRECRAWL_API_KEY=fc-74732ed0f8374552b32e8195725da1e3

# Configuration serveur
MCP_HOST=0.0.0.0
MCP_PORT=8000

