# Configuration Ollama
OLLAMA_MODEL=llama2
OLLAMA_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=mistral

# FAISS Configuration
FAISS_TYPE=cpu  # ou 'gpu' si vous avez installé faiss-gpu

# Paramètres RAG
CHUNK_SIZE=4096
CHUNK_OVERLAP=512
RAG_RESULTS=3

# API Exa/Firecrawl
SEARCH_PROVIDER=exa
EXA_API_KEY=
FIRECRAWL_API_KEY=

# Configuration serveur
MCP_HOST=0.0.0.0
MCP_PORT=8000